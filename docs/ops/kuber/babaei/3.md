# APIs

- [**Kubernetes API Ref**](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/)

## [Workloads](https://kubernetes.io/docs/concepts/workloads/)

## [Replica Set](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/)

A ReplicaSet's purpose is to maintain a stable set of replica Pods running at any given time. As such, it is often used to guarantee the availability of a specified number of identical Pods.

### How a ReplicaSet works

A ReplicaSet is defined with fields, including a selector that specifies how to identify Pods it can acquire, a number of replicas indicating how many Pods it should be maintaining, and a pod template specifying the data of new Pods it should create to meet the number of replicas criteria. A ReplicaSet then fulfills its purpose by creating and deleting Pods as needed to reach the desired number. When a ReplicaSet needs to create new Pods, it uses its Pod template.

### [Scaling a ReplicaSet](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/#scaling-a-replicaset)

A ReplicaSet can be easily scaled up or down by simply updating the `.spec.replicas` field. The ReplicaSet controller ensures that a desired number of Pods with a matching label selector are available and operational.

### ReplicaSet APIs

- [ReplicaSet v1 apps](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#replicaset-v1-apps)
- [ReplicationController v1 core](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#replicationcontroller-v1-core)

**Note:** The most important tag that we should use in workload is: [Label Selectors](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors)

## [Deployment Set](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)

A Deployment provides declarative updates for Pods and ReplicaSets.

You describe a `desired state` in a Deployment, and the Deployment Controller changes the actual state to the `desired state` at a controlled rate. You can define Deployments to create new ReplicaSets, or to remove existing Deployments and adopt all their resources with new Deployments.

### [Use Case](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#use-case)

- Create a Deployment to rollout a ReplicaSet.
- Declare the new state of the Pods.
- Rollback to an earlier Deployment.
- Scale up the Deployment to facilitate more load.
- Pause the rollout of a Deployment.
- Use the status of the Deployment.
- Clean up older ReplicaSets.

### DeploymentSet APIs

- [Deployment v1 apps](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#deployment-v1-apps)

## [Labels and Selectors](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/)

Labels are `key/value` pairs that are attached to objects such as Pods.

### [Label selectors](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors)

The API currently supports two types of selectors: [**equality-based**](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#equality-based-requirement) and [**set-based**](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#set-based-requirement). A label selector can be made of multiple requirements which are comma-separated. In the case of multiple requirements, all must be satisfied so the `comma` separator acts as a `logical AND (&&)` operator.

## [Namespace](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/)

In Kubernetes, _namespaces_ provides a mechanism for isolating groups of resources within a single cluster. Names of resources need to be unique within a namespace, but not across namespaces. Namespace-based scoping is applicable only for namespaced **_objects_** (e.g. Deployments, Services, etc) and not for cluster-wide objects (e.g. StorageClass, Nodes, PersistentVolumes, etc).

### Change default namespace

> kubectl config set-context --current --namespace=\<ns-name\>

### [Namespaces and DNS](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/#namespaces-and-dns)

When you create a [Service](https://kubernetes.io/docs/concepts/services-networking/service/), it creates a corresponding [DNS entry](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/). This entry is of the form `<service-name>.<namespace-name>.svc.cluster.local`, which means that if a container only uses `<service-name>`, it will resolve to the service which is local to a namespace. This is useful for using the same configuration across multiple namespaces such as Development, Staging and Production. If you want to reach across namespaces, you need to use the fully qualified domain name (FQDN).

### Namespace APIs

- [Namespace v1 core](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#namespace-v1-core)

## [Resource Quotas](https://kubernetes.io/docs/concepts/policy/resource-quotas/)

When several users or teams share a cluster with a fixed number of nodes, there is a concern that one team could use more than its fair share of resources.

Resource quotas are a tool for administrators to address this concern.

### [Resource quotas API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#resourcequota-v1-core)

## [Service](https://kubernetes.io/docs/concepts/services-networking/service/)

In Kubernetes, a Service is a method for exposing a network application that is running as one or more Pods in your cluster.

- Enable communication <ins>between various component</ins> **_within_** and **_outside_** of application.

- Help us **_connect application_** together with other applications or users

### [Service type](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types)

Kubernetes Service types allow you to specify what kind of Service you want.

The available `type` values and their behaviors are:

- #### [ClusterIP](https://kubernetes.io/docs/concepts/services-networking/service/#type-clusterip)

  Exposes the Service on a **_cluster-internal IP_**. Choosing this value makes the Service only reachable from within the cluster. This is the default that is used if you don't explicitly specify a `type` for a Service. You can expose the Service to the public internet using an [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/) or a [Gateway](https://gateway-api.sigs.k8s.io/).

  **Calling a clusterIP via DNS in _Different_ Namespace**

  ```shell
  kubectl -n <namespace-name> exec <pod-name> -- curl <service-name>.<namespace>.svc.cluster.local:<target-port>
  ```

  **Calling a clusterIP via DNS in _Same_ Namespace**

  ```shell
  kubectl exec <pod-name> -- curl <service-name>:<target-port>
  ```

- #### [NodePort](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport)

  Exposes the Service on each Node's IP at a static port (the NodePort). To make the node port available, Kubernetes sets up a cluster IP address, the same as if you had requested a Service of type: ClusterIP.

- #### [LoadBalancer](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer)

  Exposes the Service externally using an external load balancer. Kubernetes does not directly offer a load balancing component; you must provide one, or you can integrate your Kubernetes cluster with a cloud provider.

- #### [ExternalName](https://kubernetes.io/docs/concepts/services-networking/service/#externalname)

  Maps the Service to the contents of the externalName field (for example, to the hostname api.foo.bar.example). The mapping configures your cluster's DNS server to return a CNAME record with that external hostname value. No proxying of any kind is set up.

### [Port Forward](https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/#forward-a-local-port-to-a-port-on-the-pod)

```bash
kubectl port-forward <resource-type>/<resourcename> 8080:80
kubectl port-forward service/nginx-internal 80:8000
```

### Service Type Schema

<img src="../../../../assets/cicd/kuber/docs/babaei/S03-service-02.jpg" width="50%" height="50%" >

<img src="../../../../assets/cicd/kuber/docs/babaei/S03-service-01.png" width="50%" height="50%" >

<img src="../../../../assets/cicd/kuber/docs/babaei/S03-service-03.png" width="50%" height="50%" alt="Explain Service Ports" >

## [Schedular](https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/)

### [Taint & Tolerance](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)

Node affinity is a property of Pods that attracts them to a set of nodes (either as a preference or a hard requirement). Taints are the opposite -- they allow a node to repel a set of pods.

Tolerations are applied to pods. Tolerations allow the scheduler to schedule pods with matching taints. Tolerations allow scheduling but don't guarantee scheduling: the scheduler also evaluates other parameters as part of its function.

Taints and tolerations work together to ensure that pods are not scheduled onto inappropriate nodes. One or more taints are applied to a node; this marks that the node should not accept any pods that do not tolerate the taints.

#### Concepts

You add a taint to a node using kubectl taint. For example,

```bash
kubectl taint nodes node1 key1=value1:NoSchedule
```

places a taint on node `node1`. The taint has key `key1`, value `value1`, and [_**taint effect**_](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/#taint-based-evictions) _`NoSchedule`_. This means that no pod will be able to schedule onto node1 unless it has a matching toleration.

To remove the taint added by the command above, you can run:

```bash
kubectl taint nodes node1 key1=value1:NoSchedule-
```

## Commands

```bash
kubectl explain <config-kind>
kubectl explain resourcequota
kubectl explain resourcequota.spec
kubectl explain resourcequota.spec.hard
kubectl get rs -o wide
kubectl apply -f <manifest-filename.yml>
kubectl delete -f <manifest-filename.yml>
[kubectl scale](https://kubernetes.io/docs/reference/kubectl/cheatsheet/#scaling-resources)
kubectl get namespace
kubectl get ns
kubectl create namespace <ns-name>
kubectl get -n <ns-name> pods
kubectl describe <ns-name>
kubectl -n <ns-name> events
kubectl get pods --all-namespaces
```
